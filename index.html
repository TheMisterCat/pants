<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>SMRT Radio</title>
<link rel="icon" href="data:,">
<style>
  body {
    font-family: sans-serif;
    background: #111;
    color: #eee;
    margin: 0;
    display: flex;
    flex-direction: column;
    align-items: center;
  }
  header {
    text-align: center;
    margin: 1em;
  }
  #controls {
    display: flex;
    gap: 10px;
    margin: 1em;
    align-items: center;
    flex-wrap: wrap;
    justify-content: center;
  }
  button {
    padding: 0.5em 1em;
    background: #222;
    border: 1px solid #444;
    border-radius: 0.5em;
    color: #eee;
    cursor: pointer;
    transition: background 0.2s;
  }
  button:hover {
    background: #333;
  }
  #sliders {
    display: flex;
    gap: 10px;
    align-items: center;
    flex-wrap: wrap;
  }
  #playlist {
    margin-top: 1em;
    width: 90%;
    max-width: 800px;
    overflow-y: auto;
    max-height: 300px;
  }
  .track {
    padding: 0.5em;
    cursor: pointer;
    border-bottom: 1px solid #444;
  }
  .track.playing {
    background: #333;
  }
  #progress {
    width: 300px;
    margin-top: 1em;
  }
  #waveform {
    width: 90%;
    max-width: 800px;
    height: 100px;
    background: #222;
    margin-top: 1em;
  }
</style>
</head>
<body>
<header><h1>SMRT Radio</h1></header>

<div id="controls">
  <button id="prev">‚èÆÔ∏è Prev</button>
  <button id="play">‚ñ∂Ô∏è Play</button>
  <button id="stop">‚èπÔ∏è Stop</button>
  <button id="next">Next ‚è≠Ô∏è</button>
  <div id="sliders">
    <label>üîä Volume:
      <input type="range" id="volume" min="0" max="1" step="0.01" value="0.2">
    </label>
  </div>
</div>

<progress id="progress" value="0" max="1"></progress>
<canvas id="waveform"></canvas>
<div id="playlist"></div>

<script type="module">
// --- CONFIG ---
const REPO = "TheMisterCat/pants";
const AUDIO_DIR = "";
const VOLUME_SCALING = 1.0;

// --- AUDIO SETUP ---
const audioContext = new (window.AudioContext || window.webkitAudioContext)();
const masterGainNode = audioContext.createGain();
const filterNode = audioContext.createBiquadFilter();
filterNode.type = "lowpass";
filterNode.frequency.value = 9800;
masterGainNode.connect(filterNode);
filterNode.connect(audioContext.destination);

const analyser = audioContext.createAnalyser();
analyser.fftSize = 2048;
// connect analyser from the same node feeding destination so waveform is visible
filterNode.connect(analyser);

// --- STATE ---
let currentSource = null;        // currently playing AudioBufferSourceNode
let currentSourceOnEnded = null; // saved onended handler so we can detach it
let currentTrackIndex = 0;
let trackBuffers = [];
let playlist = [];
let lastButtonTime = 0;
const BUTTON_COOLDOWN = 250;
let userStopped = false;
let loadingPromises = {}; // to avoid duplicate concurrent loads

class Decoder {
  /**
   * Port of node-dfpwm Decoder to browser JS.
   * Constructor: (fq, q, s, lt) where fq is filter state, q is charge, s is strength, lt is last target.
   */
  constructor(fq, q, s, lt) {
    this.fq = fq || 0;
    this.q  = q  || 0;
    this.s  = s  || 0;
    this.lt = lt || -128;
  }

  /**
   * Decode 1-bit DFPWM data (Uint8Array or ArrayBuffer view) to Float32Array PCM samples.
   * fs default matches node-dfpwm CONST_POSTFILT (140).
   * Returns Float32Array of length buffer.length * 8 with samples in [-1, 1).
   */
  decode(buffer, fs = 140) {
    // ensure we can access bytes
    const input = buffer instanceof Uint8Array ? buffer : new Uint8Array(buffer);

    const CONST_PREC = 10;         // match node-dfpwm
    const outLen = input.length * 8;
    const out = new Float32Array(outLen);
    let outpos = 0;

    for (let i = 0; i < input.length; i++) {
      // read byte
      let d = input[i];
      for (let j = 0; j < 8; j++) {
        // target sample: 127 or -128
        const t = (d & 1) ? 127 : -128;
        d >>= 1;

        // adjust charge
        let nq = this.q + ((this.s * (t - this.q) + (1 << (CONST_PREC - 1))) >> CONST_PREC);
        if (nq === this.q && nq !== t) this.q += (t === 127 ? 1 : -1);
        const lq = this.q;
        this.q = nq;

        // adjust strength
        const st = (t !== this.lt ? 0 : (1 << CONST_PREC) - 1);
        let ns = this.s;
        if (ns !== st) ns += (st !== 0 ? 1 : -1);
        if (CONST_PREC > 8 && ns < (1 << (CONST_PREC - 7))) ns = (1 << (CONST_PREC - 7));
        this.s = ns;

        // FILTER: perform antijerk
        let ov = (t !== this.lt ? (nq + lq + 1) >> 1 : nq);

        // FILTER: perform LPF (postfilter)
        this.fq += ((fs * (ov - this.fq) + 0x80) >> 8);
        ov = this.fq;

        // convert signed 8-bit (-128..127) to float roughly in [-1,1)
        out[outpos++] = ov / 128; // same scaling used previously
        this.lt = t;
      }
    }

    return out;
  }
}
const decoder = new Decoder();

// --- FETCH PLAYLIST ---
async function fetchPlaylist() {
  try {
    const url = `https://api.github.com/repos/${REPO}/contents/${AUDIO_DIR}`;
    const res = await fetch(url);
    const files = await res.json();
    playlist = (Array.isArray(files) ? files : []).filter(f => f.name && f.name.endsWith(".dfpwm")).map(f => f.name);
  } catch (e) {
    console.error("Failed to fetch playlist:", e);
    playlist = [];
  }

  const listDiv = document.getElementById("playlist");
  listDiv.innerHTML = "";
  playlist.forEach((name, idx) => {
    const div = document.createElement("div");
    div.textContent = name;
    div.classList.add("track");
    div.onclick = () => safePlay(idx);
    listDiv.appendChild(div);
  });
  highlightPlaying();
}

// --- LOAD & DECODE ---
async function loadTrack(idx) {
  // avoid duplicate concurrent loads for same index
  if (trackBuffers[idx]) return trackBuffers[idx];
  if (loadingPromises[idx]) return loadingPromises[idx];

  const p = (async () => {
    const url = `https://raw.githubusercontent.com/${REPO}/main/${AUDIO_DIR}${playlist[idx]}`;
    const res = await fetch(url);
    const bytes = new Uint8Array(await res.arrayBuffer());
    const floatData = decoder.decode(bytes);
    // create buffer at 48000Hz as before
    const buffer = audioContext.createBuffer(1, floatData.length, 48000);
    buffer.copyToChannel(floatData, 0, 0);
    trackBuffers[idx] = buffer;
    delete loadingPromises[idx];
    return buffer;
  })();

  loadingPromises[idx] = p;
  return p;
}

// --- UTILS for safe source stop/cleanup ---
function detachAndStopCurrentSource() {
  if (!currentSource) return;
  try {
    // detach onended to prevent previous source firing change-of-track logic
    if (currentSourceOnEnded) {
      try { currentSource.removeEventListener('ended', currentSourceOnEnded); } catch(e) {}
      currentSourceOnEnded = null;
    } else {
      // also try setting onended to null in case it was assigned directly
      try { currentSource.onended = null; } catch(e) {}
    }
    // stop the node (safe-guard in try/catch)
    try { currentSource.stop(0); } catch(e) {}
  } finally {
    currentSource = null;
  }
}

// --- PLAYBACK ---
async function playTrack(idx) {
  // ensure audioContext resumed on user gesture
  if (audioContext.state === 'suspended') {
    try { await audioContext.resume(); } catch (e) { /*ignore*/ }
  }

  // stop and fully detach any existing source before creating a new one
  detachAndStopCurrentSource();

  currentTrackIndex = idx;
  highlightPlaying();

  // ensure buffer loaded (await if necessary)
  if (!trackBuffers[idx]) {
    try {
      await loadTrack(idx);
    } catch (e) {
      console.error("failed to load track", idx, e);
      return;
    }
  }

  // If user has manually stopped (userStopped === true), clear that because we're intentionally starting playback now.
  userStopped = false;

  const source = audioContext.createBufferSource();
  source.buffer = trackBuffers[idx];
  source.connect(masterGainNode);
  currentSource = source;

  // attach a stable onended handler and save it so we can remove it if we stop the source manually
  const onEnded = () => {
    // only auto-advance if we didn't intentionally stop
    currentSource = null;
    currentSourceOnEnded = null;
    if (!userStopped) {
      nextTrack(true); // indicate autoplay transition
    }
    highlightPlaying();
  };
  currentSourceOnEnded = onEnded;
  // prefer addEventListener for easier removal
  try {
    source.addEventListener('ended', onEnded);
  } catch (e) {
    // fallback
    source.onended = onEnded;
  }

  // start playback
  try {
    source.start(0);
  } catch (e) {
    console.error("Error starting source:", e);
    // cleanup on error
    detachAndStopCurrentSource();
    return;
  }
}

function stopTrack() {
  if (currentSource) {
    // mark that user intentionally stopped playback so onended handlers don't auto-advance
    userStopped = true;
    detachAndStopCurrentSource();
    highlightPlaying();
  }
}

function nextTrack(fromAutoplay = false) {
  if (!playlist.length) return;
  // if called by autoplay, only proceed when autoplay triggers it (userStopped should be false)
  // compute next index and play
  const next = (currentTrackIndex + 1) % playlist.length;
  // start next track; this is a deliberate play so ensure userStopped=false
  userStopped = false;
  playTrack(next);
}

function prevTrack() {
  if (!playlist.length) return;
  const prev = (currentTrackIndex - 1 + playlist.length) % playlist.length;
  userStopped = false;
  playTrack(prev);
}

// --- SAFETY WRAPPERS ---
function safeAction(action) {
  const now = performance.now();
  if (now - lastButtonTime < BUTTON_COOLDOWN) return;
  lastButtonTime = now;
  action();
}
function safePlay(idx) {
  safeAction(() => {
    // user wants to play this track: ensure we treat it as an intentional play
    userStopped = false;
    // stop current source immediately and start the new one
    detachAndStopCurrentSource();
    playTrack(idx);
  });
}
function safeStop() { safeAction(stopTrack); }
function safeNext() { safeAction(() => { userStopped = false; nextTrack(); }); }
function safePrev() { safeAction(() => { userStopped = false; prevTrack(); }); }

function highlightPlaying() {
  document.querySelectorAll(".track").forEach((el, idx) => {
    el.classList.toggle("playing", idx === currentTrackIndex);
  });
}

// --- UI LISTENERS ---
document.getElementById("play").onclick = () => safePlay(currentTrackIndex);
document.getElementById("stop").onclick = safeStop;
document.getElementById("next").onclick = safeNext;
document.getElementById("prev").onclick = safePrev;

// --- SLIDERS ---
const volumeSlider = document.getElementById("volume");

volumeSlider.addEventListener("input", e => {
  masterGainNode.gain.value = parseFloat(e.target.value) * VOLUME_SCALING;
});

// Apply initial slider values immediately
masterGainNode.gain.value = parseFloat(volumeSlider.value) * VOLUME_SCALING;

// --- VISUALIZER ---
const canvas = document.getElementById("waveform");
const ctx = canvas.getContext("2d");

function resizeCanvasForDisplay() {
  const rect = canvas.getBoundingClientRect();
  const ratio = window.devicePixelRatio || 1;
  const w = Math.max(1, Math.floor(rect.width * ratio));
  const h = Math.max(1, Math.floor(rect.height * ratio));
  if (canvas.width !== w || canvas.height !== h) {
    canvas.width = w;
    canvas.height = h;
    ctx.setTransform(1, 0, 0, 1, 0, 0);
    ctx.scale(ratio, ratio);
  }
}
window.addEventListener('resize', resizeCanvasForDisplay);
resizeCanvasForDisplay();

function drawWaveform() {
  requestAnimationFrame(drawWaveform);

  // --- Resize canvas to match display size ---
  const displayWidth  = canvas.clientWidth;
  const displayHeight = canvas.clientHeight;
  if (canvas.width !== displayWidth || canvas.height !== displayHeight) {
    canvas.width  = displayWidth;
    canvas.height = displayHeight;
  }
  const width = canvas.width;
  const height = canvas.height;

  // Short fade for trail effect
  ctx.fillStyle = "rgba(0, 0, 0, 0.2)";
  ctx.fillRect(0, 0, width, height);

  // Time-domain waveform
  const bufferLength = analyser.fftSize;
  const timeData = new Uint8Array(bufferLength);
  analyser.getByteTimeDomainData(timeData);

  // Frequency-domain data for color
  const freqData = new Uint8Array(analyser.frequencyBinCount);
  analyser.getByteFrequencyData(freqData);

  // Bass amplitude for subtle pulse
  let bass = 0;
  const bassBins = 16;
  for (let i = 0; i < bassBins; i++) bass += freqData[i];
  bass = bass / bassBins / 255;
  const bassPulse = 1 + bass * 0.1; // smaller exaggeration for centered waveform

  // --- Glow / Bloom layers ---
  function drawGlow(color, blur, alpha) {
    ctx.save();
    ctx.lineWidth = 4;
    ctx.globalAlpha = alpha;
    ctx.shadowColor = color;
    ctx.shadowBlur = blur;
    ctx.strokeStyle = color;
    ctx.beginPath();

    let x = 0;
    for (let i = 0; i < bufferLength; i++) {
      const v = timeData[i] / 128.0 - 1; // center around 0
      const y = (v * height / 2) * bassPulse + height / 2;
      if (i === 0) ctx.moveTo(x, y);
      else ctx.lineTo(x, y);
      x += width / bufferLength;
    }
    ctx.stroke();
    ctx.restore();
  }

  drawGlow("rgba(255,255,255,0.5)", 25, 0.10);
  drawGlow("rgba(255,255,255,0.8)", 12, 0.15);
  drawGlow("rgba(255,255,255,1.0)", 5, 0.20);

  // --- Main multicolor waveform ---
  ctx.lineWidth = 2;
  let x = 0;
  const sliceWidth = width / bufferLength;

  for (let i = 1; i < bufferLength; i++) {
    const v1 = timeData[i - 1] / 128.0 - 1; // center around 0
    const v2 = timeData[i] / 128.0 - 1;
    const y1 = (v1 * height / 2) * bassPulse + height / 2;
    const y2 = (v2 * height / 2) * bassPulse + height / 2;

    const freqIndex = Math.floor((i / bufferLength) * freqData.length);
    const amp = freqData[freqIndex] / 255;
    const freqRatio = freqIndex / freqData.length;

    const hue = freqRatio * 300;
    const light = 40 + amp * 35;
    const saturation = 90;

    ctx.strokeStyle = `hsl(${hue}, ${saturation}%, ${light}%)`;
    ctx.beginPath();
    ctx.moveTo(x, y1);
    ctx.lineTo(x + sliceWidth, y2);
    ctx.stroke();

    x += sliceWidth;
  }

  // --- Removed bass-reactive background ---
}
drawWaveform();

// --- INIT ---
fetchPlaylist();
</script>
</body>
</html>








